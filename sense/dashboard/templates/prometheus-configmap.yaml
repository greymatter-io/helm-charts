kind: ConfigMap
apiVersion: v1
metadata:
  name: prometheus
  namespace: {{ .Release.Namespace }}
data:
  prometheus.yaml: |-
    global:
      scrape_interval:     5s
      evaluation_interval: 2m

    # References the recording rules YAML file below
    rule_files:
      - "/etc/prometheus/recording_rules.yaml"

    scrape_configs:

      - job_name: 'prometheus'
        static_configs:
          - targets: ['localhost:9090']
      {{- if .Values.global.consul.enabled }}
      - job_name: consul
        metrics_path: /prometheus
        consul_sd_configs:
        - server: '{{ .Values.global.consul.host }}:{{ .Values.global.consul.port }}'
        relabel_configs:
          - source_labels: ['__meta_consul_service_metadata_metrics']
            regex: '(\d+)'
            action: 'keep'
          - source_labels: ['__meta_consul_service_address', '__meta_consul_service_metadata_metrics']
            regex: '(.*);(\d+)'
            replacement: '${1}:${2}'
            target_label: __address__
          - source_labels: ['__meta_consul_service']
            target_label: job
      {{- else }}
      - job_name: kubernetes
        metrics_path: /prometheus
        kubernetes_sd_configs:
          - role: pod
            namespaces:
              names:
{{ include "greymatter.dashboard.prometheus_namespaces" . | indent 16 }}
        relabel_configs:
        # Drop all named ports that are not "metrics"
        - source_labels: ['__meta_kubernetes_pod_container_port_name']
          regex: 'metrics'
          action: 'keep'
        # Relabel Jobs to the service name and version of the zk path
        - source_labels: ['__meta_kubernetes_pod_label_gmproxy']
          regex: '(.*)'
          target_label:  'job'
          #replacement:   '${1}'
          replacement:   '${1}'
      {{- end }}
      - job_name: 'gm-metrics'
        metrics_path: /prometheus
        kubernetes_sd_configs:
          - role: pod
            namespaces:
              names:
{{ include "greymatter.dashboard.prometheus_namespaces" . | indent 16 }}
        relabel_configs:
        # Drop all named ports that are not "metrics"
        - source_labels: ['__meta_kubernetes_pod_container_port_name']
          regex: 'metrics'
          action: 'keep'
        # Relabel Jobs to the service name and version of the zk path
        - source_labels: ['__meta_kubernetes_pod_label_gmproxy']
          regex: '(.*)'
          target_label:  'job'
          #replacement:   '${1}'
          replacement:   '${1}'
      - job_name: 'envoy-metrics'
        metrics_path: /stats/prometheus
        kubernetes_sd_configs:
          - role: pod
            namespaces:
              names:
{{ include "greymatter.dashboard.prometheus_namespaces" . | indent 16 }}
        relabel_configs:
        # Drop all named ports that are not "metrics"
        - source_labels: ['__meta_kubernetes_pod_container_port_name']
          regex: 'metrics'
          action: 'keep'
        # Relabel Jobs to the service name and version of the zk path
        - source_labels: ['__meta_kubernetes_pod_label_gmproxy']
          regex: '(.*)'
          target_label:  'job'
          #replacement:   '${1}'
          replacement:   '${1}'
        - source_labels: ['__address__']
          regex: '(.*):(.*)'
          target_label:  '__address__'
          replacement:   '${1}:8001'

  # Copied from https://github.com/DecipherNow/gm-dashboard/blob/master/docker/prometheus/recording_rules.yml
  recording_rules.yaml: |-
    # Dashboard version: 3.4.0
    # time intervals:
    # ["1h", "4h", "12h"]

    groups:
      # queries for overall services
      - name: overviewQueries
        rules:
          - record: overviewQueries:avgUpPercent:avg
            expr: avg by (job) (up)
          # avgResponseTimeByRoute
          - record: overviewQueries:avgResponseTimeByRoute_1h:avg
            expr: avg(rate(http_request_duration_seconds_sum{key!="all"}[1h]) / rate(http_request_duration_seconds_count{key!="all"}[1h]) * 1000 > 0) by (job, key)
          - record: overviewQueries:avgResponseTimeByRoute_4h:avg
            expr: avg(rate(http_request_duration_seconds_sum{key!="all"}[4h]) / rate(http_request_duration_seconds_count{key!="all"}[4h]) * 1000 > 0) by (job, key)
          - record: overviewQueries:avgResponseTimeByRoute_12h:avg
            expr: avg(rate(http_request_duration_seconds_sum{key!="all"}[12h]) / rate(http_request_duration_seconds_count{key!="all"}[12h]) * 1000 > 0) by (job, key)
            # numberOfRequestsByRoute
          - record: overviewQueries:numberOfRequestsByRoute_1h:sum
            expr: sum(floor(increase(http_request_duration_seconds_count[1h])) >= 1) by (job, key)
          - record: overviewQueries:numberOfRequestsByRoute_4h:sum
            expr: sum(floor(increase(http_request_duration_seconds_count[4h])) >= 1) by (job, key)
          - record: overviewQueries:numberOfRequestsByRoute_12h:sum
            expr: sum(floor(increase(http_request_duration_seconds_count[12h])) >= 1) by (job, key)
            # latencyByRoute
          - record: overviewQueries:latencyByRoute_1h:sum
            expr: sum without(instance, status)(rate(http_request_duration_seconds_count{key!="all"}[1h])) > 0
          - record: overviewQueries:latencyByRoute_4h:sum
            expr: sum without(instance, status)(rate(http_request_duration_seconds_count{key!="all"}[4h])) > 0
          - record: overviewQueries:latencyByRoute_12h:sum
            expr: sum without(instance, status)(rate(http_request_duration_seconds_count{key!="all"}[12h])) > 0
            # error percent
          - record: overviewQueries:errorPercent_1h:sum
            expr: sum(floor(increase(http_request_duration_seconds_count{status!~"2..|3..", key!="all"}[1h]) )) by (job) / sum(floor(increase(http_request_duration_seconds_count{key!="all"}[1h]) )) by (job) * 100
          - record: overviewQueries:errorPercent_4h:sum
            expr: sum(floor(increase(http_request_duration_seconds_count{status!~"2..|3..", key!="all"}[4h]) )) by (job) / sum(floor(increase(http_request_duration_seconds_count{key!="all"}[4h]) )) by (job) * 100
          - record: overviewQueries:errorPercent_12h:sum
            expr: sum(floor(increase(http_request_duration_seconds_count{status!~"2..|3..", key!="all"}[12h]) )) by (job) / sum(floor(increase(http_request_duration_seconds_count{key!="all"}[12h]) )) by (job) * 100

        # queries for each route
      - name: queriesByRoute
        rules:
          # error percent
          - record: queriesByRoute:errorPercent_1h:sum
            expr: sum(floor(increase(http_request_duration_seconds_count{status!~"2..|3..", key!="all"}[1h]) )) by (job, key, method) / sum(floor(increase(http_request_duration_seconds_count{key!="all"}[1h]) )) by (job, key, method) * 100
          - record: queriesByRoute:errorPercent_4h:sum
            expr: sum(floor(increase(http_request_duration_seconds_count{status!~"2..|3..", key!="all"}[4h]) )) by (job, key, method) / sum(floor(increase(http_request_duration_seconds_count{key!="all"}[4h]) )) by (job, key, method) * 100
          - record: queriesByRoute:errorPercent_12h:sum
            expr: sum(floor(increase(http_request_duration_seconds_count{status!~"2..|3..", key!="all"}[12h]) )) by (job, key, method) / sum(floor(increase(http_request_duration_seconds_count{key!="all"}[12h]) )) by (job, key, method) * 100
            # p95Latency
          - record: queriesByRoute:p95Latency_1h:sum
            expr: round(histogram_quantile(0.95,avg without(instance, status)(rate(http_request_duration_seconds_bucket[1h]))) * 1000, 0.1)
          - record: queriesByRoute:p95Latency_4h:sum
            expr: round(histogram_quantile(0.95,avg without(instance, status)(rate(http_request_duration_seconds_bucket[4h]))) * 1000, 0.1)
          - record: queriesByRoute:p95Latency_12h:sum
            expr: round(histogram_quantile(0.95,avg without(instance, status)(rate(http_request_duration_seconds_bucket[12h]))) * 1000, 0.1)
            # p50 latency
          - record: queriesByRoute:p50Latency_1h:sum
            expr: round(histogram_quantile(0.50,avg without(instance, status)(rate(http_request_duration_seconds_bucket[1h]))) * 1000, 0.1)
          - record: queriesByRoute:p50Latency_4h:sum
            expr: round(histogram_quantile(0.50,avg without(instance, status)(rate(http_request_duration_seconds_bucket[4h]))) * 1000, 0.1)
          - record: queriesByRoute:p50Latency_12h:sum
            expr: round(histogram_quantile(0.50,avg without(instance, status)(rate(http_request_duration_seconds_bucket[12h]))) * 1000, 0.1)
            # request count for route
          - record: queriesByRoute:requestCount_1h:sum
            expr: sum(floor(increase(http_request_duration_seconds_count[1h])) >= 1) by (job, key, method)
          - record: queriesByRoute:requestCount_4h:sum
            expr: sum(floor(increase(http_request_duration_seconds_count[4h])) >= 1) by (job, key, method)
          - record: queriesByRoute:requestCount_12h:sum
            expr: sum(floor(increase(http_request_duration_seconds_count[12h])) >= 1) by (job, key, method)

        # range queries
      - name: rangeQueries
        rules:
          # pXXLatency range queries
          - record: rangeQueries:p50Latency:sum
            expr: round(histogram_quantile(0.50,avg without(instance, status)(rate(http_request_duration_seconds_bucket[10m]))) * 1000, 0.1)
          - record: rangeQueries:p90Latency:sum
            expr: round(histogram_quantile(0.90,avg without(instance, status)(rate(http_request_duration_seconds_bucket[10m]))) * 1000, 0.1)
          - record: rangeQueries:p95Latency:sum
            expr: round(histogram_quantile(0.95,avg without(instance, status)(rate(http_request_duration_seconds_bucket[10m]))) * 1000, 0.1)
          - record: rangeQueries:p99Latency:sum
            expr: round(histogram_quantile(0.99,avg without(instance, status)(rate(http_request_duration_seconds_bucket[10m]))) * 1000, 0.1)
          - record: rangeQueries:p999Latency:sum
            expr: round(histogram_quantile(0.999,avg without(instance, status)(rate(http_request_duration_seconds_bucket[10m]))) * 1000, 0.1)
          - record: rangeQueries:p9999Latency:sum
            expr: round(histogram_quantile(0.9999,avg without(instance, status)(rate(http_request_duration_seconds_bucket[10m]))) * 1000, 0.1)
            # error percent by (job, key)
          - record: rangeQueries:errorPercent:sum
            expr: sum(floor(increase(http_request_duration_seconds_count{status!~"2..|3..", key!="all"}[1m]) )) by (job, key) / sum(floor(increase(http_request_duration_seconds_count{key!="all"}[1m]) )) by (job, key) * 100
            # respones time per bucket
          - record: rangeQueries:responseTimeP50:sum
            expr: round(histogram_quantile(0.50,avg without(instance, status, key, method)(rate(http_request_duration_seconds_bucket{key!="all"}[10m]))) * 1000, 0.1)
          - record: rangeQueries:responseTimeP90:sum
            expr: round(histogram_quantile(0.90,avg without(instance, status, key, method)(rate(http_request_duration_seconds_bucket{key!="all"}[10m]))) * 1000, 0.1)
          - record: rangeQueries:responseTimeP95:sum
            expr: round(histogram_quantile(0.95,avg without(instance, status, key, method)(rate(http_request_duration_seconds_bucket{key!="all"}[10m]))) * 1000, 0.1)
          - record: rangeQueries:responseTimeP99:sum
            expr: round(histogram_quantile(0.99,avg without(instance, status, key, method)(rate(http_request_duration_seconds_bucket{key!="all"}[10m]))) * 1000, 0.1)
          - record: rangeQueries:responseTimeP999:sum
            expr: round(histogram_quantile(0.999,avg without(instance, status, key, method)(rate(http_request_duration_seconds_bucket{key!="all"}[10m]))) * 1000, 0.1)
          - record: rangeQueries:responseTimeP9999:sum
            expr: round(histogram_quantile(0.9999,avg without(instance, status, key, method)(rate(http_request_duration_seconds_bucket{key!="all"}[10m]))) * 1000, 0.1)

            # error violation
          - record: rangeQueries:errorViolation:sum
            expr: (1 - (sum without(instance, status, key, method)(rate(http_request_duration_seconds_count{key!="all",status=~"2..|3.."}[1m]))) / (sum without(instance, status, key, method)(rate(http_request_duration_seconds_count{key!="all"}[1m])))) * 100
            # requests violation
          - record: rangeQueries:requestRateViolation:sum
            expr: sum without(instance, status, key, method)(rate(http_request_duration_seconds_count{key!="all"}[1m]))
            # request violations for route violation
          - record: rangeQueries:routeRequestViolations:sum
            expr: sum without(instance, status, method)(rate(http_request_duration_seconds_count[1m]))
            # route latencies
          - record: rangeQueries:routep50LatencyViolations:sum
            expr: histogram_quantile(0.50,avg without(instance, status)(rate(http_request_duration_seconds_bucket[10m])))
          - record: rangeQueries:routep90LatencyViolations:sum
            expr: histogram_quantile(0.90,avg without(instance, status)(rate(http_request_duration_seconds_bucket[10m])))
          - record: rangeQueries:routep95LatencyViolations:sum
            expr: histogram_quantile(0.95,avg without(instance, status)(rate(http_request_duration_seconds_bucket[10m])))
          - record: rangeQueries:routep99LatencyViolations:sum
            expr: histogram_quantile(0.99,avg without(instance, status)(rate(http_request_duration_seconds_bucket[10m])))
          - record: rangeQueries:routep999LatencyViolations:sum
            expr: histogram_quantile(0.999,avg without(instance, status)(rate(http_request_duration_seconds_bucket[10m])))
          - record: rangeQueries:routep9999LatencyViolations:sum
            expr: histogram_quantile(0.9999,avg without(instance, status)(rate(http_request_duration_seconds_bucket[10m])))
            