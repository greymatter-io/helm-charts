apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: {{ .Values.controlApi.name }}
  namespace: {{ .Release.Namespace }}
spec:
  serviceName: {{ .Values.controlApi.name }}
  replicas: {{ .Values.controlApi.replicas }}
  updateStrategy:
    type: RollingUpdate
  selector:
    matchLabels:
      {{ .Values.global.control.cluster_label }}: {{ .Values.controlApi.name }}
      deployment: {{ .Values.controlApi.name }}
  template:
    metadata:
      labels:
        {{ .Values.global.control.cluster_label }}: {{ .Values.controlApi.name }}
        deployment: {{ .Values.controlApi.name }}
    spec:
      # Security context for openshift, kubernetes and eks is the same. 
      securityContext:
        runAsUser: 2000
        runAsGroup: 0
        fsGroup: 2000
      containers:
        - name: {{ .Values.controlApi.name }}
          image: {{ tpl .Values.controlApi.image $ }}
          imagePullPolicy: {{ .Values.controlApi.image_pull_policy }}
          env:
            {{- include "envvars" (dict "envvar" .Values.controlApi.envvars "top" $) | indent 10 }}
          ports:
            - name: http
              containerPort: {{ .Values.controlApi.container_port }}
              protocol: TCP
          {{- if not .Values.controlApi.secret.enabled }}
          # We don't want to kill the container if it's taking a while to start up, we'll just remove it from the service
          readinessProbe:
            httpGet:
              path: /v1.0/cluster
              port: http
              httpHeaders:
                # For production we'll need a valid authentication credential here
                # We may want to create a separate healthcheck endpoint to remove this issue
                - name: Authorization
                  value: Bearer xxx
            # Pods are considered to be in a Failure state before the initialDelaySeconds has passed, meaning they won't be backends for a service
            initialDelaySeconds: 5
            periodSeconds: 2
          # We want to restart the container if it's failed 3 requests spaced 3 seconds apart after we've given it quite enough time to start up and be initialized
          # We give a full minute before we start health-checking for failures
          livenessProbe:
            httpGet:
              path: /v1.0/cluster
              port: http
              httpHeaders:
                - name: Authorization
                  value: Bearer xxx
            initialDelaySeconds: 60
            periodSeconds: 3
          {{- end }}
          {{- if .Values.resources }}
          resources:
{{ toYaml .Values.resources | indent 12 }}
          {{- end }}
          volumeMounts:
            {{- if .Values.controlApi.secret.enabled }}
            - name: service-certs
              mountPath: {{ .Values.controlApi.secret.mount_point }}
            {{- end }}
            - name: control-api-backup
              mountPath: {{ dir .Values.controlApi.pvc_mount_point }}
        - name: sidecar   
          image: {{ tpl .Values.sidecar.image $ | quote }}
          imagePullPolicy: {{ .Values.sidecar.image_pull_policy }}
          {{- if .Values.sidecar.resources }}
          resources:
{{ toYaml .Values.sidecar.resources | indent 12 }}
          {{- end }}
          ports:
            - name: proxy
              containerPort: {{ .Values.sidecar.port }}
            - name: metrics
              containerPort: {{ .Values.sidecar.metrics_port }}
          # If mTLS is enabled on the service, we can't use normal httpGet probes. Instead we add the probes to the sidecar so that we can exec in and call the service directly. The control-api service does not have the utilities (curl, wget with ssl) we need to do these probes there.
          {{- if .Values.global.spire.enabled }}
          {{- else if .Values.sidecar.secret.enabled }}
          # We don't want to kill the container if it's taking a while to start up, we'll just remove it from the service
          readinessProbe:
            exec:
              command:
                - /bin/sh
                - -c
                - "curl -k --cacert /etc/proxy/tls/sidecar/ca.crt --key /etc/proxy/tls/sidecar/server.key --cert /etc/proxy/tls/sidecar/server.crt https://localhost:5555/v1.0/cluster"
            # Pods are considered to be in a Failure state before the initialDelaySeconds has passed, meaning they won't be backends for a service
            initialDelaySeconds: 5
            periodSeconds: 2
          # We want to restart the container if it's failed 3 requests spaced 3 seconds apart after we've given it quite enough time to start up and be initialized
          # We give a full minute before we start health-checking for failures
          livenessProbe:
            exec:
              command:
                - /bin/sh
                - -c
                - "curl -k --cacert {{ .Values.sidecar.secret.mount_point }}/{{ .Values.sidecar.secret.secret_keys.ca }} --key  {{ .Values.sidecar.secret.mount_point }}/{{ .Values.sidecar.secret.secret_keys.key }} --cert  {{ .Values.sidecar.secret.mount_point }}/{{ .Values.sidecar.secret.secret_keys.cert }} https://localhost:5555/v1.0/cluster"
            initialDelaySeconds: 60
            periodSeconds: 3
          {{- end }}
          env:
          {{- include "sidecar.envvars" . | indent 12 }}
            {{- if .Values.global.spire.enabled }}
            - name: SPIRE_PATH
              value: {{ .Values.global.spire.path }}
            {{- end }}
          volumeMounts:
          {{- if .Values.global.spire.enabled }}
          {{- include "spire_volume_mount" . | indent 12 }}
          {{- else if .Values.sidecar.secret.enabled }}
          {{- include "sidecar_volume_certs_mount" . | indent 12 }}
          {{- end }}
        {{- if .Values.global.consul.enabled }}
        {{- $data := dict "Values" .Values "ServiceName" .Values.controlApi.name }}
        {{- include "consul.agent" $data | nindent 8 }}
        {{- end }}
      imagePullSecrets:
      - name: {{ .Values.global.image_pull_secret }}
      volumes:
      {{- if .Values.controlApi.secret.enabled }}
      - name: service-certs
        secret:
          {{- if .Values.global.global_certs.enabled }}
          secretName: global-certs
          {{- else }}
          secretName: {{ .Values.controlApi.secret.secret_name }}
          {{- end }}
      {{- end }}
      {{- if .Values.global.consul.enabled }}
      - name: data-consul
        emptyDir: {}
      - name: config-consul
        emptyDir: {}
      {{- end }}
      {{- if .Values.global.spire.enabled }}
      {{- include "spire_volumes" . | indent 6 }}
      {{- else if .Values.sidecar.secret.enabled }}
      {{- include "sidecar_certs_volumes" . | indent 6 }}
      {{- end }}
  volumeClaimTemplates:
  - metadata:
      name: control-api-backup 
    spec:
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: {{ .Values.controlApi.pvc.size | default "1Gi" }}